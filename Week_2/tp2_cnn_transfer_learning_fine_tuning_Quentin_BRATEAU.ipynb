{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "tp2_cnn_transfer_learning_fine_tuning(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDNFLstXpOfE"
      },
      "source": [
        "# TP2: Seafloor classification par CNN \n",
        "\n",
        "## 1 - Introduction\n",
        "\n",
        "Disposant d'un ensemble d'images dont on veut prédire la classe, deux possibilités s'offrent pour apprendre un modèle profond de classement.\n",
        "\n",
        "- La première possibilité se nomme \"Transfer Learning\" associé au \"fine tuning\" dont les principes sont d'utiliser un réseau de neurones profond entrainé dans un autre contexte et de l'adapter à nos données: \n",
        "    \n",
        "- La seconde possibilité est de créer et d'entrainer un modèle profond ex-nihilo (from scratch, en partant de zéro).\n",
        "\n",
        "\n",
        "L'objectif de ce TP est d'appliquer ces deux possibilités au problème de classification de patchs d'images sonar en types de fond marin que vous avez déjà traités dans les TPs précédent. Vous reprendrez les fonctions d'import des patchs que vous avez déjà mises au point lors des tps précédents.\n",
        "\n",
        "Il pourra être néanmoins utile d'utiliser les lignes de code suivantes pour que les données soient dans la forme attendue par tensoflow/keras et éventuellement changer la taille des images:\n",
        "```python\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "target_size = 192;\n",
        "feature_values = np.array([img_to_array(load_img(img,  # color_mode = \"grayscale\",\n",
        "             target_size=(target_size, target_size))) for img in dataset_df['image_path'].values.tolist()\n",
        "]).astype('float32')\n",
        "```\n",
        "A noter que la taille des patchs est automatiquement réduite à 192x192 pixels, vous pouvez réduire cette taille en fonction des performances de votre machine. Attention, une taille trop basse peut impliquer une erreur si vous réutilisez par la suite un modèle déjà entrainé (par exemple VGG16).\n",
        "\n",
        "La création d'ensemble d'apprentissage, de validation et de test se fera en divisant la base en trois parts. Il faudrait pour ce petit jeu de données réaliser une procédure de cross-validation. Compte tenu du temps pour réaliser cette procédure, elle sera ici laissée de coté. \n",
        "\n",
        "## 1 - Tutorials CNN et transfer learning par fine tuning\n",
        "\n",
        "Dans le startercode, vous trouverez un jupyter notebooks qui vous servira de base pour réaliser la suite. Dans un premier temps, le notebook détaille le fonctionnement et la mise en oeuvre des CNNs (en particulier les différentes couches d'un CNN avec des exemples); pour ensuite détailler la procédure liée au fine tuning avec data augmentation à partir de données de type TensorFlow Dataset. \n",
        "\n",
        "Veillez à bien suivre les différentes étapes et à bien comprendre les différentes commandes employées. Si vous voulez d'autres exemples, vous trouverez d'autres ressources supplémentaires.\n",
        "\n",
        "\n",
        "## 2 - Transfer learning par fine tuning sur le dataset seafloor\n",
        "\n",
        "- Vous commencerez par le fine tuning en vous inspirant du tuto fourni ci-dessus pour faire du transfer learning du modèle xception (dont les paramètres ont été appris sur la base d'images \"imageNet\") pour l'appliquer aux patchs d'images sonar. Vous procéderez ainsi:\n",
        "  - les modèles sont téléchargeables ici si vous avez des problèmes pour télécharger: https://drive.google.com/open?id=1qFwqoNU1fsvl8fu-7eRCmjoPNZZNzPSJ\n",
        "  - Résumer l'approche du transfer learning/fine tuning\n",
        "\n",
        "L'idée du transfert learning est d'utiliser un modèle déjà entrainé par d'autres personnes ayant des moyens matériels plus importants que notre pc pour entrainer le modèle. Par la suite, on réutilise les possibilités offertes par ce réseau de neurones en terme d'extraction de features afin d'alimenter les dernières couches de notre modèle propre à notre problème, ici de classification. Il ne nous reste que ces dernières couches à entrainer afin d'avoir un modèle opérationnel.\n",
        "\n",
        "  - Décriver l'architecture du modèle utilisé (xception ici)\n",
        "\n",
        "L'idée des réseaux inceptions dont xception fait parti est de réaliser en parallèle 3 traitements de convolution 1x1 suivis d'une convolution 3x3 et de concaténer les sorties de ces trois branches pour former un block. Ensuite ces blocks sont chainés afin d'être réutilisés plusieurs fois et de pouvoir avoir un modèle plus complexe. Cette architecture offre des résultats assez satisfaisants.\n",
        "\n",
        "  - Vous précisérez votre choix concernant les paramètres des fonctions appelées en particulier expliquer votre démarche concernant les phases de preprocessing des images, de data augmentation, de classification, etc.\n",
        "  - remarque: comme les images sonar sont en niveaux de gris et que le modèle VGG prend en entrée des images couleurs, il s'agira de dupliquer ce canal sur les canaux R, G et B. \n",
        "\n",
        "  - Enfin, vous évaluerez les performances obtenues.\n",
        "- (Bonus) comparez les résultats obtenus par l'architecture vgg16 (https://keras.io/applications/).\n",
        "\n",
        "- (Bonus) Essayez et comparez les résultats obtenus par d'autres architectures (Resnet, Inception etc...https://keras.io/applications/).\n",
        "\n",
        "## 3 - Proposition de votre propre achitecture  \n",
        "\n",
        "- Vous proposerez ensuite une architecture de réseau profond convolutif et évaluerez ses performances. \n",
        "- Expliquez brièvement votre architecture et en particulier à quoi servent les couches (et leur enchainement) de votre architecture.\n",
        "- Vous comparerez ensuite les performances obtenus (par rapport à ceux obtenus à la partie précédente) sur la matrice de confusion et les métriques de performance classiques.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# A rendre \n",
        "- pour le **12/01/21**\n",
        "- la séance du 05/01/21 sera consacrée à finaliser\n",
        "- **Commenter au maximum votre code (pourquoi vous utilisez tel ou tel bout de code) ou apporter des précisions dans votre CR.**\n",
        "- au choix (**N'oublier pas les deux noms en cas de binômes**):\n",
        "    - un fichier zip avec *.py et un cr au format pdf\n",
        "    - un fichier .ipynb avec compte-rendu et code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQvreloXpOfP"
      },
      "source": [
        "# 4 - Aide pour démarrer\n",
        "\n",
        "## 4.1 Chargement des données\n",
        "Vous pourrez utiliser cette procédure pour charger les données: \n",
        "**A noter**\n",
        "- target_size permet de définir un éventuel changement de taille des images qui pourra servir en fonction de la taille d'entrée du modèle que vous considérez.\n",
        "- comme les images sonar sont en niveaux de gris et que le modèle VGG prend en entrée des images couleurs, load_img duplique ce canal sur les canaux R, G et B."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKH0ZSMzpOfR",
        "outputId": "9d5bdd75-76d1-428e-e543-9aedb3142190"
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import pandas as pd\n",
        "import os \n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "import sys\n",
        "IN_COLAB = 'google.colab' in sys.modules\n",
        "\n",
        "# Paramètres\n",
        "if IN_COLAB:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "    os.chdir(\"/content/drive/MyDrive/Machine_Learning\")\n",
        "    DATASET_PATH = \"./dataset/imgs/\"\n",
        "    LABEL_PATH = \"./dataset/labels/labels.csv\"\n",
        "    from pythonTools import *\n",
        "else:\n",
        "    IN_COLAB = False\n",
        "    DATASET_PATH = r'./dataset/imgs/'\n",
        "    LABEL_PATH = r'./dataset/labels/labels.csv'\n",
        "\n",
        "target_size = 200\n",
        "dataset_df = pd.read_csv(LABEL_PATH)\n",
        "\n",
        "# We add another column to the labels dataset to identify image path\n",
        "dataset_df['image_path'] = dataset_df.apply(lambda row: (DATASET_PATH + row[\"id\"]), axis=1)\n",
        "\n",
        "batch_imgs = np.array([img_to_array(\n",
        "    load_img(img, color_mode = \"grayscale\",\n",
        "             target_size=(target_size, target_size))\n",
        ") for img\n",
        "    in dataset_df['image_path'].values.tolist()\n",
        "]).astype('float32')\n",
        "\n",
        "#  Noms des labels dans l'ordre, respectivement aux indices\n",
        "labelNames_unique = np.array([\"Posidonia\",\"Ripple 45°\",\"Ripple vertical\",\"Rock\",\"Sand\",\"Silt\"])\n",
        "labelDict={}\n",
        "for i in range(len(labelNames_unique)):\n",
        "    labelDict.update({i:labelNames_unique[i]})\n",
        "\n",
        "# Récupération des labels\n",
        "label_names = dataset_df['seafloor']\n",
        "\n",
        "# nb de classes\n",
        "label_nb = labelNames_unique.shape[0]\n",
        "\n",
        "# indices\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(labelNames_unique)\n",
        "labelIndices_unique = le.transform(labelNames_unique)\n",
        "labelIndices  = le.transform(label_names)\n",
        "\n",
        "# one-hot-encoding\n",
        "labelOhe = pd.get_dummies(label_names.reset_index(drop=True)).values"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnXRuk5UumEl",
        "outputId": "872dfed0-8ea6-4348-a137-0a627bd8c17a"
      },
      "source": [
        "print(batch_imgs.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(360, 200, 200, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bPpX7FLpOfT"
      },
      "source": [
        "## 4.2 - Définition, entrainer et évaleur le modèle VGG16 (par exemple) pour le fine tuning\n",
        "Ensuite procéder comme le tuto:\n",
        "- charger le modèle VGG16 sans le classifieur include_top=False\n",
        "- Visualiser l'architecture du modèle: model.summary()\n",
        "- Créer un modèle d'extraction d'information (features) allant de la couche d'entrée de VGG16 jusqu'à sa dernière couche de convolution nommée 'block3_pool'\n",
        "- Rajouter des couches Dense pour définir un classifieur Fully connected (attention aux nombres de sorties de la dernière couche et à sa fonction d'activation)\n",
        "- ne pas oublier l'étape de preprocessing essentiel à la bonne réussite de l'apprentissage. Il faut se renseigner sur les corrections à apporter et la taille des images d'entrée\n",
        "- Compiler (compile), entrainer (fit) et évaluer (evaluate) le modèle\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6CkjHSotmIe"
      },
      "source": [
        "# Importing the required libraries\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPool2D, Flatten, Dense\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9XE2UX6pwJBK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11d2d7d5-358b-4412-e691-b5a84ab6176f"
      },
      "source": [
        "# Spliting data into a training and a testing dataset\n",
        "data_train, data_test, labels_train, labels_test = train_test_split(batch_imgs, label_names, test_size=0.20, random_state=42)\n",
        "print(data_train.shape, data_test.shape, labels_train.shape, labels_test.shape)\n",
        "labels_train = le.transform(labels_train)\n",
        "labels_test = le.transform(labels_test)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(288, 200, 200, 1) (72, 200, 200, 1) (288,) (72,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHYln41l776p"
      },
      "source": [
        "# The CNN expects 224 × 224 images, so we need\n",
        "# to resize them. We also need to run the image through Xception’s preprocess_input() function:\n",
        "    \n",
        "def preprocess(image):\n",
        "    resized_image = tf.image.resize(image, [224, 224])\n",
        "    final_image = keras.applications.xception.preprocess_input(resized_image)\n",
        "    return final_image"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GwFTO_Z78up",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feb29f14-4c60-4565-c1c3-7278133a8e40"
      },
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_set = []\n",
        "for k in range(len(data_train)):\n",
        "  img = preprocess(data_train[i])\n",
        "  img=np.stack((img[:,:,0],)*3,axis=-1)\n",
        "  img=tf.Variable(img,trainable=True)\n",
        "  train_set.append(img)\n",
        "\n",
        "test_set = []\n",
        "for k in range(len(data_test)):\n",
        "  img = preprocess(data_test[i])\n",
        "  img=np.stack((img[:,:,0],)*3,axis=-1)\n",
        "  img=tf.Variable(img,trainable=True)\n",
        "  test_set.append(img)\n",
        "    \n",
        "# Creating a StandardScaler()\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "# Getting statistical indicators from the dataset and normalizing training and testing data\n",
        "\n",
        "train_set=tf.convert_to_tensor(train_set)\n",
        "test_set=tf.convert_to_tensor(test_set)\n",
        "\n",
        "\n",
        "print(train_set.shape,test_set.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(288, 224, 224, 3) (72, 224, 224, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "806BiJdm8o-U"
      },
      "source": [
        "# chargement du feature extractor (sans classifieur include_top=False)\n",
        "base_model = keras.applications.xception.Xception(weights=\"imagenet\",\n",
        "                                                  include_top=False)\n",
        "\n",
        "# on rajoute séquentiellement des couches de classification\n",
        "n_classes = 6\n",
        "avg = keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "output = keras.layers.Dense(n_classes, activation=\"softmax\")(avg)\n",
        "\n",
        "# on a recréé le modèle en liant l'entrée de base_model à la sortie \n",
        "model = keras.models.Model(inputs=base_model.input, outputs=output)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4uqJX1R83jO",
        "outputId": "a4943a26-a5ca-4f33-c758-6d501713268c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, None, None,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1 (Conv2D)           (None, None, None, 3 864         input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_bn (BatchNormaliza (None, None, None, 3 128         block1_conv1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv1_act (Activation)   (None, None, None, 3 0           block1_conv1_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2 (Conv2D)           (None, None, None, 6 18432       block1_conv1_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_bn (BatchNormaliza (None, None, None, 6 256         block1_conv2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "block1_conv2_act (Activation)   (None, None, None, 6 0           block1_conv2_bn[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1 (SeparableConv2 (None, None, None, 1 8768        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv1_bn (BatchNormal (None, None, None, 1 512         block2_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_act (Activation (None, None, None, 1 0           block2_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2 (SeparableConv2 (None, None, None, 1 17536       block2_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block2_sepconv2_bn (BatchNormal (None, None, None, 1 512         block2_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 1 8192        block1_conv2_act[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block2_pool (MaxPooling2D)      (None, None, None, 1 0           block2_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 1 512         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, None, None, 1 0           block2_pool[0][0]                \n",
            "                                                                 batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_act (Activation (None, None, None, 1 0           add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1 (SeparableConv2 (None, None, None, 2 33920       block3_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv1_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_act (Activation (None, None, None, 2 0           block3_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2 (SeparableConv2 (None, None, None, 2 67840       block3_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block3_sepconv2_bn (BatchNormal (None, None, None, 2 1024        block3_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 2 32768       add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block3_pool (MaxPooling2D)      (None, None, None, 2 0           block3_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 2 1024        conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, None, None, 2 0           block3_pool[0][0]                \n",
            "                                                                 batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_act (Activation (None, None, None, 2 0           add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1 (SeparableConv2 (None, None, None, 7 188672      block4_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_act (Activation (None, None, None, 7 0           block4_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block4_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block4_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block4_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 7 186368      add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block4_pool (MaxPooling2D)      (None, None, None, 7 0           block4_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 7 2912        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, None, None, 7 0           block4_pool[0][0]                \n",
            "                                                                 batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_act (Activation (None, None, None, 7 0           add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_act (Activation (None, None, None, 7 0           block5_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_act (Activation (None, None, None, 7 0           block5_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block5_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block5_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block5_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, None, None, 7 0           block5_sepconv3_bn[0][0]         \n",
            "                                                                 add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_act (Activation (None, None, None, 7 0           add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_act (Activation (None, None, None, 7 0           block6_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_act (Activation (None, None, None, 7 0           block6_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block6_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block6_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block6_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, None, None, 7 0           block6_sepconv3_bn[0][0]         \n",
            "                                                                 add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_act (Activation (None, None, None, 7 0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_act (Activation (None, None, None, 7 0           block7_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_act (Activation (None, None, None, 7 0           block7_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block7_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block7_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block7_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, None, None, 7 0           block7_sepconv3_bn[0][0]         \n",
            "                                                                 add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_act (Activation (None, None, None, 7 0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_act (Activation (None, None, None, 7 0           block8_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_act (Activation (None, None, None, 7 0           block8_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block8_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block8_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block8_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, None, None, 7 0           block8_sepconv3_bn[0][0]         \n",
            "                                                                 add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_act (Activation (None, None, None, 7 0           add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv1_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv1_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_act (Activation (None, None, None, 7 0           block9_sepconv1_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv2_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv2_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_act (Activation (None, None, None, 7 0           block9_sepconv2_bn[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3 (SeparableConv2 (None, None, None, 7 536536      block9_sepconv3_act[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block9_sepconv3_bn (BatchNormal (None, None, None, 7 2912        block9_sepconv3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "add_31 (Add)                    (None, None, None, 7 0           block9_sepconv3_bn[0][0]         \n",
            "                                                                 add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_act (Activatio (None, None, None, 7 0           add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1 (SeparableConv (None, None, None, 7 536536      block10_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_act (Activatio (None, None, None, 7 0           block10_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2 (SeparableConv (None, None, None, 7 536536      block10_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_act (Activatio (None, None, None, 7 0           block10_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3 (SeparableConv (None, None, None, 7 536536      block10_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block10_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block10_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_32 (Add)                    (None, None, None, 7 0           block10_sepconv3_bn[0][0]        \n",
            "                                                                 add_31[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_act (Activatio (None, None, None, 7 0           add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1 (SeparableConv (None, None, None, 7 536536      block11_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_act (Activatio (None, None, None, 7 0           block11_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2 (SeparableConv (None, None, None, 7 536536      block11_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_act (Activatio (None, None, None, 7 0           block11_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3 (SeparableConv (None, None, None, 7 536536      block11_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block11_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block11_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_33 (Add)                    (None, None, None, 7 0           block11_sepconv3_bn[0][0]        \n",
            "                                                                 add_32[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_act (Activatio (None, None, None, 7 0           add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1 (SeparableConv (None, None, None, 7 536536      block12_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_act (Activatio (None, None, None, 7 0           block12_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2 (SeparableConv (None, None, None, 7 536536      block12_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv2_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_act (Activatio (None, None, None, 7 0           block12_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3 (SeparableConv (None, None, None, 7 536536      block12_sepconv3_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block12_sepconv3_bn (BatchNorma (None, None, None, 7 2912        block12_sepconv3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "add_34 (Add)                    (None, None, None, 7 0           block12_sepconv3_bn[0][0]        \n",
            "                                                                 add_33[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_act (Activatio (None, None, None, 7 0           add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1 (SeparableConv (None, None, None, 7 536536      block13_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv1_bn (BatchNorma (None, None, None, 7 2912        block13_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_act (Activatio (None, None, None, 7 0           block13_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2 (SeparableConv (None, None, None, 1 752024      block13_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block13_sepconv2_bn (BatchNorma (None, None, None, 1 4096        block13_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 1 745472      add_34[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block13_pool (MaxPooling2D)     (None, None, None, 1 0           block13_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 1 4096        conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_35 (Add)                    (None, None, None, 1 0           block13_pool[0][0]               \n",
            "                                                                 batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1 (SeparableConv (None, None, None, 1 1582080     add_35[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_bn (BatchNorma (None, None, None, 1 6144        block14_sepconv1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv1_act (Activatio (None, None, None, 1 0           block14_sepconv1_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2 (SeparableConv (None, None, None, 2 3159552     block14_sepconv1_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_bn (BatchNorma (None, None, None, 2 8192        block14_sepconv2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block14_sepconv2_act (Activatio (None, None, None, 2 0           block14_sepconv2_bn[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 6)            12294       global_average_pooling2d_2[0][0] \n",
            "==================================================================================================\n",
            "Total params: 20,873,774\n",
            "Trainable params: 20,819,246\n",
            "Non-trainable params: 54,528\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_4nG7V28N4M",
        "outputId": "d14291db-76fc-4f80-8790-3d520f20a14a"
      },
      "source": [
        "# Principe du fine-tuning = on fixe le feature extractor pendant l'apprentissage\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Since our model uses the base model’s layers directly, rather than the base_model object itself \n",
        "# (i.e. on a recréé le modèle à partir des layers avec l'appel à keras.models.Model), \n",
        "# setting base_model.trainable=False\n",
        "# would have no effect.\n",
        "\n",
        "# apprentissage\n",
        "optimizer = keras.optimizers.SGD(lr=0.001, momentum=0.9, decay=0.01)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "dataset_size = 360\n",
        "history = model.fit(tf.convert_to_tensor(train_set), labels_train, epochs=50, \n",
        "                    validation_data=(tf.convert_to_tensor(test_set), labels_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "9/9 [==============================] - 4s 280ms/step - loss: 1.7943 - accuracy: 0.1515 - val_loss: 1.8015 - val_accuracy: 0.1944\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 2s 189ms/step - loss: 1.7897 - accuracy: 0.1728 - val_loss: 1.8018 - val_accuracy: 0.1944\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 2s 191ms/step - loss: 1.7855 - accuracy: 0.2137 - val_loss: 1.8022 - val_accuracy: 0.1944\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 2s 189ms/step - loss: 1.7878 - accuracy: 0.1974 - val_loss: 1.8018 - val_accuracy: 0.1944\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 2s 191ms/step - loss: 1.7941 - accuracy: 0.1397 - val_loss: 1.8011 - val_accuracy: 0.1944\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 2s 190ms/step - loss: 1.7902 - accuracy: 0.1568 - val_loss: 1.8015 - val_accuracy: 0.1944\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 2s 190ms/step - loss: 1.7921 - accuracy: 0.1747 - val_loss: 1.8019 - val_accuracy: 0.1944\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 2s 191ms/step - loss: 1.7903 - accuracy: 0.1859 - val_loss: 1.8026 - val_accuracy: 0.1944\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 2s 191ms/step - loss: 1.7870 - accuracy: 0.1982 - val_loss: 1.8020 - val_accuracy: 0.1944\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 2s 192ms/step - loss: 1.7853 - accuracy: 0.2091 - val_loss: 1.8016 - val_accuracy: 0.1944\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 2s 192ms/step - loss: 1.7867 - accuracy: 0.2017 - val_loss: 1.8017 - val_accuracy: 0.1944\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 1.7906 - accuracy: 0.1795 - val_loss: 1.8011 - val_accuracy: 0.1944\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 2s 193ms/step - loss: 1.7923 - accuracy: 0.1809 - val_loss: 1.8011 - val_accuracy: 0.1944\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 2s 194ms/step - loss: 1.7895 - accuracy: 0.1747 - val_loss: 1.8017 - val_accuracy: 0.1944\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.7912 - accuracy: 0.2156 - val_loss: 1.8018 - val_accuracy: 0.1944\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.7920 - accuracy: 0.1831 - val_loss: 1.8019 - val_accuracy: 0.1944\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 1.7899 - accuracy: 0.1743 - val_loss: 1.8020 - val_accuracy: 0.1944\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 1.7885 - accuracy: 0.1655 - val_loss: 1.8020 - val_accuracy: 0.1944\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 1.7903 - accuracy: 0.1628 - val_loss: 1.8019 - val_accuracy: 0.1944\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.7888 - accuracy: 0.1878 - val_loss: 1.8016 - val_accuracy: 0.1944\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.7946 - accuracy: 0.1562 - val_loss: 1.8014 - val_accuracy: 0.1944\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.7928 - accuracy: 0.1213 - val_loss: 1.8016 - val_accuracy: 0.1944\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.7902 - accuracy: 0.2252 - val_loss: 1.8016 - val_accuracy: 0.1944\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 1.7923 - accuracy: 0.1425 - val_loss: 1.8017 - val_accuracy: 0.1944\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.7898 - accuracy: 0.1890 - val_loss: 1.8019 - val_accuracy: 0.1944\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 1.7972 - accuracy: 0.1415 - val_loss: 1.8018 - val_accuracy: 0.1944\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.7956 - accuracy: 0.1587 - val_loss: 1.8017 - val_accuracy: 0.1944\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.7911 - accuracy: 0.1993 - val_loss: 1.8017 - val_accuracy: 0.1944\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.7879 - accuracy: 0.1940 - val_loss: 1.8018 - val_accuracy: 0.1944\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.7901 - accuracy: 0.1805 - val_loss: 1.8018 - val_accuracy: 0.1944\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.7864 - accuracy: 0.1954 - val_loss: 1.8020 - val_accuracy: 0.1944\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 1.7842 - accuracy: 0.2107 - val_loss: 1.8020 - val_accuracy: 0.1944\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.7929 - accuracy: 0.1952 - val_loss: 1.8016 - val_accuracy: 0.1944\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 1.7854 - accuracy: 0.1930 - val_loss: 1.8019 - val_accuracy: 0.1944\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 1.7858 - accuracy: 0.2009 - val_loss: 1.8017 - val_accuracy: 0.1944\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 1.7902 - accuracy: 0.1771 - val_loss: 1.8016 - val_accuracy: 0.1944\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.7906 - accuracy: 0.1722 - val_loss: 1.8015 - val_accuracy: 0.1944\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 2s 196ms/step - loss: 1.7869 - accuracy: 0.1793 - val_loss: 1.8018 - val_accuracy: 0.1944\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.7916 - accuracy: 0.1591 - val_loss: 1.8016 - val_accuracy: 0.1944\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 1.7879 - accuracy: 0.1893 - val_loss: 1.8016 - val_accuracy: 0.1944\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.7906 - accuracy: 0.1706 - val_loss: 1.8016 - val_accuracy: 0.1944\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 2s 196ms/step - loss: 1.7894 - accuracy: 0.1871 - val_loss: 1.8016 - val_accuracy: 0.1944\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 2s 196ms/step - loss: 1.7927 - accuracy: 0.1867 - val_loss: 1.8015 - val_accuracy: 0.1944\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.7877 - accuracy: 0.1911 - val_loss: 1.8018 - val_accuracy: 0.1944\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.7962 - accuracy: 0.1765 - val_loss: 1.8016 - val_accuracy: 0.1944\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.7906 - accuracy: 0.1863 - val_loss: 1.8017 - val_accuracy: 0.1944\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.7859 - accuracy: 0.2046 - val_loss: 1.8018 - val_accuracy: 0.1944\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.7901 - accuracy: 0.1952 - val_loss: 1.8017 - val_accuracy: 0.1944\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 1.7878 - accuracy: 0.2190 - val_loss: 1.8017 - val_accuracy: 0.1944\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 1.7871 - accuracy: 0.1864 - val_loss: 1.8019 - val_accuracy: 0.1944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMiCkpQY9IgL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "717dcc9c-eeb3-416c-b958-3220f2f829e9"
      },
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = True\n",
        "\n",
        "optimizer = keras.optimizers.SGD(learning_rate=0.01, momentum=0.9,\n",
        "                                 nesterov=True, decay=0.001)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "dataset_size = 360\n",
        "history = model.fit(tf.convert_to_tensor(train_set), labels_train, epochs=20, \n",
        "                    validation_data=(tf.convert_to_tensor(test_set), labels_test))\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "9/9 [==============================] - 10s 743ms/step - loss: 1.8013 - accuracy: 0.2018 - val_loss: 1.7935 - val_accuracy: 0.1944\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 6s 671ms/step - loss: 1.7923 - accuracy: 0.1601 - val_loss: 1.8008 - val_accuracy: 0.2083\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 6s 674ms/step - loss: 1.7994 - accuracy: 0.1662 - val_loss: 1.8002 - val_accuracy: 0.0972\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 6s 685ms/step - loss: 1.7900 - accuracy: 0.2006 - val_loss: 1.8012 - val_accuracy: 0.0972\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 6s 688ms/step - loss: 1.7893 - accuracy: 0.2183 - val_loss: 1.8006 - val_accuracy: 0.0972\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 6s 677ms/step - loss: 1.7885 - accuracy: 0.1816 - val_loss: 1.7961 - val_accuracy: 0.0972\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 6s 672ms/step - loss: 1.7879 - accuracy: 0.1896 - val_loss: 1.7939 - val_accuracy: 0.0972\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 6s 674ms/step - loss: 1.7850 - accuracy: 0.2108 - val_loss: 1.7947 - val_accuracy: 0.0972\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 6s 666ms/step - loss: 1.7905 - accuracy: 0.1782 - val_loss: 1.7929 - val_accuracy: 0.2083\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 6s 668ms/step - loss: 1.7882 - accuracy: 0.1967 - val_loss: 1.7924 - val_accuracy: 0.2083\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 6s 663ms/step - loss: 1.7867 - accuracy: 0.2018 - val_loss: 1.7961 - val_accuracy: 0.1111\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 6s 666ms/step - loss: 1.7916 - accuracy: 0.1861 - val_loss: 1.8018 - val_accuracy: 0.0972\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 6s 668ms/step - loss: 1.7899 - accuracy: 0.1558 - val_loss: 1.8070 - val_accuracy: 0.0972\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 6s 674ms/step - loss: 1.7940 - accuracy: 0.1563 - val_loss: 1.8123 - val_accuracy: 0.0972\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 6s 678ms/step - loss: 1.7900 - accuracy: 0.1977 - val_loss: 1.8216 - val_accuracy: 0.0972\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 6s 673ms/step - loss: 1.7930 - accuracy: 0.1738 - val_loss: 1.8344 - val_accuracy: 0.0972\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 6s 671ms/step - loss: 1.7915 - accuracy: 0.1681 - val_loss: 1.8506 - val_accuracy: 0.0972\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 6s 674ms/step - loss: 1.7885 - accuracy: 0.1949 - val_loss: 1.8837 - val_accuracy: 0.0972\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 6s 674ms/step - loss: 1.7901 - accuracy: 0.1869 - val_loss: 1.9331 - val_accuracy: 0.0972\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 6s 672ms/step - loss: 1.7864 - accuracy: 0.1978 - val_loss: 2.0317 - val_accuracy: 0.0972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kcXNsiXpOfT"
      },
      "source": [
        "## 4.3 - Custom CNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd32xfpe-FcO",
        "outputId": "7c23e946-6d98-4136-e679-2266e1d77636"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(batch_imgs, labelIndices, test_size = 0.25, random_state = 0)\n",
        "\n",
        "X_train /= 255.\n",
        "X_test /= 255.\n",
        "\n",
        "x_tr = []\n",
        "for m in X_train:\n",
        "  x_tr.append(m.flatten())\n",
        "\n",
        "x_te = []\n",
        "for m in X_test:\n",
        "  x_te.append(m.flatten())\n",
        "\n",
        "X_train, X_test = np.asarray(x_tr), np.asarray(x_te)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(270, 40000) (270,) (90, 40000) (90,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9nJel2Mf820T",
        "outputId": "53e7676c-edff-415d-87e3-bd39989c28f2"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense \n",
        "from keras.layers import Dropout\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "#Fonction de construction du CNN\n",
        "def build_classifier(optimizer='adam'):\n",
        "    # Initialising the CNN\n",
        "    classifier = Sequential()\n",
        "\n",
        "    # Step 4 - Full connection\n",
        "    classifier.add(Dense(units = 128, activation = 'relu',input_dim = 40000))\n",
        "    classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "    #classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "\n",
        "    classifier.add(Dense(units = 6, activation = 'softmax'))\n",
        "\n",
        "    # Compiling the CNN\n",
        "    classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
        "    return classifier\n",
        "\n",
        "#Instance du classifier\n",
        "classifier = KerasClassifier(build_fn = build_classifier)\n",
        "\n",
        "parameters = {'batch_size': [30, 60],\n",
        "              'epochs': [5, 10, 15],\n",
        "              'optimizer': ['adam']}\n",
        "#Création de la grille d'entraînement.\n",
        "grid_search = GridSearchCV(estimator = classifier,\n",
        "                           param_grid = parameters,\n",
        "                           scoring = 'accuracy',\n",
        "                           cv = 5)\n",
        "\n",
        "grid_search = grid_search.fit(X_train, y_train, verbose=0)\n",
        "best_parameters = grid_search.best_params_\n",
        "best_accuracy = grid_search.best_score_\n",
        "print(best_accuracy,best_parameters)\n",
        "score = grid_search.score(X_test, y_test)\n",
        "print(score)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7861bdd90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd786687950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd786687e18> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd78757f488> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd41c8061e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd40061bf28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7874f5d08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7866d1950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd41cb756a8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7870f2400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7870f2840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7b2a72c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7b3eb2400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7b2c0bae8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd404268ea0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd41df581e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd787742c80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:7 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7875650d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd787696158> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:8 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd41ded4840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd402850a60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:9 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd787696378> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd419c857b8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:10 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7877a1620> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 12 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7877a18c8> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7861b2268> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd4041c4f28> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd787181b70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd400f2f840> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7ba06b1e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.1814814814814815 {'batch_size': 30, 'epochs': 5, 'optimizer': 'adam'}\n",
            "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fd7b2c0bd08> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "0.17777777777777778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1vEZi9WpOfX"
      },
      "source": [
        "On remarque que les différents résultats obtenus ne sont pas à la hauteur de mes attentes. On obtient environ une accuracy de 20% ce qui n'est pas exceptionnel. On remarque cependant que les deux méthodes mennent aux mêmes résultats. J'en conclus donc que le problème vient sûrement de la mise en place du dataset. C'est quelque chose qui m'a paru assez difficile et peu trouvable sur internet puisque la plupart des dataset sont déjà formés et téléchargeables en une ligne de commande. La mise en forme de ce dataset me semble assez capricieuse et stricte.\n",
        "\n",
        "# 5 -  Ressources supplémentaires en transfer learning par fine tuning**\n",
        " En dehors des supports de cours, vous pourrez aussi vous appuyer sur:\n",
        "- Les concepts du transfer learning sont expliqués dans les liens ci-dessous:\n",
        "  - https://www.youtube.com/watch?v=FQM13HkEfBk&index=20&list=PLkDaE6sCZn6Gl29AoE31iwdVwSG-KnDzF\n",
        "  - http://cs231n.github.io/transfer-learning/\n",
        "  - https://flyyufelix.github.io/2016/10/03/fine-tuning-in-keras-part1.html et https://flyyufelix.github.io/2016/10/08/fine-tuning-in-keras-part2.html\n",
        "- Des exemples supplémentaires d'implémentation\n",
        "  - https://github.com/dipanjanS/hands-on-transfer-learning-with-python/blob/master/notebooks/Ch06%20-%20Image%20Recognition%20and%20Classification/CIFAR10_CNN_Classifier.ipynb et https://github.com/dipanjanS/hands-on-transfer-learning-with-python/blob/master/notebooks/Ch06%20-%20Image%20Recognition%20and%20Classification/CIFAR10_VGG16_Transfer_Learning_Classifier.ipynb\n",
        "  - https://github.com/dipanjanS/hands-on-transfer-learning-with-python/blob/master/notebooks/Ch06%20-%20Image%20Recognition%20and%20Classification/Dog_Breed_EDA.ipynb et https://github.com/dipanjanS/hands-on-transfer-learning-with-python/blob/master/notebooks/Ch06%20-%20Image%20Recognition%20and%20Classification/Dog_Breed_Transfer_Learning_Classifier.ipynb\n",
        "- cours et des vidéos de Stanford University: https://www.youtube.com/watch?v=wEoyxE0GP2M&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=6, https://www.youtube.com/watch?v=wEoyxE0GP2M&list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv&index=7)\n",
        " "
      ]
    }
  ]
}